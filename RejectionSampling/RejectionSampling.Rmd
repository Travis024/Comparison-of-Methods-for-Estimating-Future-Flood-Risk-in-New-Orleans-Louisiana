---
title: "Rejection Sampling"
Author: Travis Torline
---

```{r}
#Load in all necessary information for the analsis

#Begin by loading the packages we'll need
library("extRemes")
library(ncdf4)

#Parameter set data created by Tony
paramsUniform <- get(load("../output/mcmc_output_processed_uniform_13Jun2019.RData"))
paramsNormalGamma <- get(load("../output/mcmc_output_processed_normalgamma_12Jun2019.RData"))

#Load in and store
params1Uniform <- paramsUniform[[1]] #All stationary
params2Uniform <- paramsUniform[[2]] #Mu nonstationary
params3Uniform <- paramsUniform[[3]] #Sigma nonstationary
params4Uniform <- paramsUniform[[4]] #Xi nonstatioanry
params5Uniform <- paramsUniform[[5]] #Mu/Sigma nonstationary
params6Uniform <- paramsUniform[[6]] #Mu/Xi nonstationary
params7Uniform <- paramsUniform[[7]] #Sigma/Xi nonstationary
params8Uniform <- paramsUniform[[8]] #All nonstationary

params1NG <- paramsNormalGamma[[1]] #All stationary
params2NG <- paramsNormalGamma[[2]] #Mu nonstationary
params3NG <- paramsNormalGamma[[3]] #Sigma nonstationary
params4NG <- paramsNormalGamma[[4]] #Xi nonstatioanry
params5NG <- paramsNormalGamma[[5]] #Mu/Sigma nonstationary
params6NG <- paramsNormalGamma[[6]] #Mu/Xi nonstationary
params7NG <- paramsNormalGamma[[7]] #Sigma/Xi nonstationary
params8NG <- paramsNormalGamma[[8]] #All nonstationary

#Now, load in the proper sea level data and time vector
ncin <- nc_open("../ncdfFiles/SeaLevelData.nc")

#Here, we multiply by 1000 because we want LSL85 to be in millimeters
LSL85 <- ncvar_get(ncin, "LocalSeaLevel_gamma_RCP85")
LSL85 <- LSL85 * 1000

#Finally, load in a time vector
timeProj <- ncvar_get(ncin, "time_proj")

nc_close(ncin)

#Now, read in all of the CSV files and store them
params1 <- read.csv(file="../parameters_data/Data Frames/params1.csv", header=TRUE, sep=",") #All stationary
params2 <- read.csv(file="../parameters_data/Data Frames/params2.csv", header=TRUE, sep=",") #Mu nonstationary
params3 <- read.csv(file="../parameters_data/Data Frames/params3.csv", header=TRUE, sep=",") #Sigma nonstationary
params4 <- read.csv(file="../parameters_data/Data Frames/params4.csv", header=TRUE, sep=",") #Xi nonstatioanry
params5 <- read.csv(file="../parameters_data/Data Frames/params5.csv", header=TRUE, sep=",") #Sigma/Xi nonstationary
params6 <- read.csv(file="../parameters_data/Data Frames/params6.csv", header=TRUE, sep=",") #Mu/Xi nonstationary
params7 <- read.csv(file="../parameters_data/Data Frames/params7.csv", header=TRUE, sep=",") #Mu/Sigma nonstationary
params8 <- read.csv(file="../parameters_data/Data Frames/params8.csv", header=TRUE, sep=",") #All nonstationary


#The following is code from advisor Tony Wong to read in and normalize historical temperature data from NOAA
#The variables we'll need from this are 'temperature_proj' and 'time_proj'
##=============================================================================
## read_temperature_data.R
##
## read temperature data
## historical from NOAA:
##   NOAA National Centers for Environmental information, Climate at a Glance:
##   Global Time Series, published May 2017, retrieved on June 7, 2017 from
##   http://www.ncdc.noaa.gov/cag/
## future projections from CRNM under RCP8.5, part of CMIP5
##
## Questions? Tony Wong (anthony.e.wong@colorado.edu)
##=============================================================================

# read the projections temperature forcing from CRNM (CMIP5)
# note: these are in K, but going to normalize, so will take a difference and
# it's same as celsius
ncdata <- nc_open('../parameters_data/global.tas.aann.CNRM-CM5.historical+rcp85.r1i1p1.18500101-21001231.nc')
temperature_proj <- ncvar_get(ncdata, 'tas')
time_proj <- ncvar_get(ncdata, 'time')
nc_close(ncdata)

# 'time' on the netcdf ile is YYYYMMDD, where MMDD is July 2 each year (becuase
# of the averaging). so pluck off just the years
time_proj <- floor(time_proj/10000)

# read the historical forcing from NOAA
data.tmp <- read.table('../parameters_data/noaa_temperature_1880-2017.csv', header = TRUE, sep=',')
time_hist <- data.tmp$Year
temperature_hist <- data.tmp$Value

# extend historical back to 1850 with HadCRUT4
data.tmp = read.table('../parameters_data/HadCRUT.4.4.0.0.annual_ns_avg.txt')
time_hadcrut = data.tmp[,1]
temperature_hadcrut = data.tmp[,2]

# normalize all to 1901-2000
ind_norm <- which(time_hist==1901):which(time_hist==2000)
temperature_hist <- temperature_hist - mean(temperature_hist[ind_norm])

ind_norm <- which(time_hadcrut==1901):which(time_hadcrut==2000)
temperature_hadcrut <- temperature_hadcrut - mean(temperature_hadcrut[ind_norm])

ind_norm <- which(time_proj==1901):which(time_proj==2000)
temperature_proj <- temperature_proj - mean(temperature_proj[ind_norm])

# set up the forcing, wherein the historical starts, then projections finish
# 1850-1880 -- hadcrut4
# 1880-2016 -- NOAA historical
# 2017-2100 -- CRNM projection
time_forc <- min(time_hadcrut):max(time_proj)
temperature_forc <- rep(NA, length(time_forc))

ind_hadcrut <- which(time_hadcrut==time_forc[1]):(which(time_hadcrut==time_hist[1])-1)
ind_hist    <- 1:length(time_hist)
ind_proj    <- which(time_proj==(max(time_hist)+1)):which(time_proj==max(time_forc))

temperature_forc <- c(temperature_hadcrut[ind_hadcrut],
                      temperature_hist[ind_hist]      ,
                      temperature_proj[ind_proj]      )

# maximum temperature serves as an additinoal prior constraint on kappa0, kappa1
# that is, kappa1 > -kappa0/Tmax (otherwise, kappa = kappa0 + kappa1*T might be
# negative)  (not necessary for GEV models)
Tmax <- max(temperature_forc)

```

```{r}
#All of the functions that will be necesary for performing the analysis

#The following are used for calculating non-stationary GEV parameters
muNonstat <- function(mu0, mu1, time = 2016){
  newMu <- mu0 + mu1 * temperature_proj[which(time_proj == time)]
}

sigmaNonstat <- function(sigma0, sigma1, time = 2016){
  newSigma <- exp(sigma0 + sigma1 * temperature_proj[which(time_proj == time)])
}

xiNonstat <- function(xi0, xi1, time = 2016){
  newXi <- xi0 + xi1 * temperature_proj[which(time_proj == time)]
}

#THe following is used to create a density distribution for the USACE method
#As inputs, it will take seaLevelData, statParams, nonstatParams timeProj, iterations, yearStart, yearEnd, returnPeriod, uniformStart, and uniformEnd
#seaLevelData = sea level projections IN MILIMETERS
#statParams = stationary GEV parameters IN MILIMETERS
#timeProj = a vector of years for which there is sea level data
#iterations = how many times to go through the above 4 steps
#yearStart = starting year
#yearEnd = ending year
#returnPeriod = The yearly magnitude of the storm (example, a 1 in 100 year storm has a return period of 100)
#uniformStart = the starting number for the uniform distribution
#uniformEnd = the ending number for the uniform distribution

generateUSACE <- function(seaLevelData, statParams, timeProj, iterations = 2064, yearStart = 2016, yearEnd = 2065, returnPeriod = 100, uniformStart = 1.5, uniformEnd = 2){
  
  #Calculate the qevd probability given the return period passed in
  qevdProb = 1 - (1/returnPeriod)
  
  #Create a vector to store the values that we calculate for X'rp
  USACEVector <- c()
  
  
  #We want to go through this process as many times as requested
  for(i in 1:iterations){
    
    #Begin by sampling from the seaLevelData
    #Generate a random index and calculate the change from yearStart to yearEnd
    sampleIndex <- sample(1:ncol(seaLevelData), 1)
    startRow = which(timeProj == yearStart)
    endRow = which(timeProj == yearEnd)
    
    seaLevelChange <- (seaLevelData[endRow, sampleIndex] - seaLevelData[startRow, sampleIndex])
    
    #Now, sample the GEV parameters
    sampleIndex = sample(1:nrow(statParams), 1)
    sampleMu <- statParams[sampleIndex, "mu"]
    sampleSigma <- statParams[sampleIndex, "sigma"]
    sampleXi <- statParams[sampleIndex, "xi"]
  
    #Finally, sample from the uniform distribution to get the surge factor
    surgeFactor <- runif(1, uniformStart, uniformEnd)
    
    #Now, calculate the return level using the sationary parameters sampled above
    returnLevel <- qevd(qevdProb, sampleMu, sampleSigma, sampleXi)
    
    #Modify that value using the sampled surge factor and change in sea level
    returnLevel <- returnLevel + (surgeFactor * seaLevelChange)
    
    #And append the changed value to our vector of values
    USACEVector <- append(USACEVector, returnLevel)
    
  } 
  
  return(USACEVector)
  
}

BMAWeights <- function(year = 2016, qevdProb = 0.99, weightVector, paramSet = 1, iterations = 10000){
  
  
    #Get the proper dataframe using the helper functions created above
    if(paramSet == 1){
      parameterDataFrame <- getUniform(year, qevdProb)
    }else{
      parameterDataFrame <- getNG(year, qevdProb)
    }
    
    
    #Create the vector that will store all of the weighted x100 values
    #This will be the vector that the entropy is calculated from
    weightedReturnLevelVector <- c()
    
    #Repeat the process for every iteration
    for(i in 1:iterations){
      
      #Clear weightedX100 every time we start a new iteration so the values don't compound
      weightedReturnLevel <- 0
      
      #Go through every row in the dataframe passed through
      for(j in 1:ncol(parameterDataFrame)){
        
        #Find a different sample index every time
        sampleIndex = sample(1:nrow(parameterDataFrame), 1)
        
        #Then, take a sample from the row, multiply it by the correct weight, and add on to the weighted value
        weightedReturnLevel <- weightedReturnLevel + (parameterDataFrame[sampleIndex, j] * weightVector[j])
        
      }
      
      #Append the value calculated above to the list before starting a new iteration
      weightedReturnLevelVector <- append(weightedReturnLevelVector, weightedReturnLevel)
      
    }
    
    return(weightedReturnLevelVector)
    
}

#A function that returns a dataframe of return leveles from the uniform parameter set
getUniform <- function(yearStart, qevdProb){
  
    #Analyze when all parameters are staionary, params1
  params1Vector <- apply(params1Uniform, 1, function(thisRow) qevd(qevdProb, thisRow["mu"], thisRow["sigma"], thisRow["xi"]))
  
  #Analyze when mu is non-stationary
  params2Vector <- apply(params2Uniform, 1, function(thisRow) qevd(qevdProb, muNonstat(thisRow["mu0"], thisRow["mu1"], yearStart), thisRow["sigma"], thisRow["xi"]))
  
  #Analyze when Sigma non-stationary
  params3Vector <- apply(params3Uniform, 1, function(thisRow) qevd(qevdProb, thisRow["mu"], sigmaNonstat(thisRow["sigma0"], thisRow["sigma1"], yearStart), thisRow["xi"]))
  
  #Analyze when xi non-stationary
  params4Vector <- apply(params4Uniform, 1, function(thisRow) qevd(qevdProb, thisRow["mu"], thisRow["sigma"], xiNonstat(thisRow["xi0"], thisRow["xi1"], yearStart)))
  
  #Analyze when sigma, xi non-stationary
  params5Vector <- apply(params5Uniform, 1, function(thisRow) qevd(qevdProb, muNonstat(thisRow["mu0"], thisRow["mu1"], yearStart), sigmaNonstat(thisRow["sigma0"], thisRow["sigma1"], yearStart), thisRow["xi"]))
  
  #Analyze when mu, xi non-stationary
  params6Vector <- apply(params6Uniform, 1, function(thisRow) qevd(qevdProb, muNonstat(thisRow["mu0"], thisRow["mu1"], yearStart), thisRow["sigma"], xiNonstat(thisRow["xi0"], thisRow["xi1"], yearStart)))
  
  #Analyze when mu, sigma non-stationary
  params7Vector <- apply(params7Uniform, 1, function(thisRow) qevd(qevdProb, thisRow["mu"], sigmaNonstat(thisRow["sigma0"], thisRow["sigma1"], yearStart), xiNonstat(thisRow["xi0"], thisRow["xi1"], yearStart)))
  
  #Analyze when all non-stationary
  params8Vector <- apply(params8Uniform, 1, function(thisRow) qevd(qevdProb, muNonstat(thisRow["mu0"], thisRow["mu1"], yearStart), sigmaNonstat(thisRow["sigma0"], thisRow["sigma1"], yearStart), xiNonstat(thisRow["xi0"], thisRow["xi1"], yearStart)))
  
  #The final set in setting up is creating a dataframe out of these vectors
  parameterDataFrame <- data.frame(params1Vector, params2Vector, params3Vector, params4Vector, params5Vector, params6Vector, params7Vector, params8Vector)
    
}

#A function that returns a dataframe of return leveles from the normal gamma parameter set
getNG <- function(yearStart, qevdProb){
  
    #Analyze when all parameters are staionary, params1
  params1Vector <- apply(params1NG, 1, function(thisRow) qevd(qevdProb, thisRow["mu"], thisRow["sigma"], thisRow["xi"]))
  
  #Analyze when mu is non-stationary
  params2Vector <- apply(params2NG, 1, function(thisRow) qevd(qevdProb, muNonstat(thisRow["mu0"], thisRow["mu1"], yearStart), thisRow["sigma"], thisRow["xi"]))
  
  #Analyze when Sigma non-stationary
  params3Vector <- apply(params3NG, 1, function(thisRow) qevd(qevdProb, thisRow["mu"], sigmaNonstat(thisRow["sigma0"], thisRow["sigma1"], yearStart), thisRow["xi"]))
  
  #Analyze when xi non-stationary
  params4Vector <- apply(params4NG, 1, function(thisRow) qevd(qevdProb, thisRow["mu"], thisRow["sigma"], xiNonstat(thisRow["xi0"], thisRow["xi1"], yearStart)))
  
  #Analyze when sigma, xi non-stationary
  params5Vector <- apply(params5NG, 1, function(thisRow) qevd(qevdProb, muNonstat(thisRow["mu0"], thisRow["mu1"], yearStart), sigmaNonstat(thisRow["sigma0"], thisRow["sigma1"], yearStart), thisRow["xi"]))
  
  #Analyze when mu, xi non-stationary
  params6Vector <- apply(params6NG, 1, function(thisRow) qevd(qevdProb, muNonstat(thisRow["mu0"], thisRow["mu1"], yearStart), thisRow["sigma"], xiNonstat(thisRow["xi0"], thisRow["xi1"], yearStart)))
  
  #Analyze when mu, sigma non-stationary
  params7Vector <- apply(params7NG, 1, function(thisRow) qevd(qevdProb, thisRow["mu"], sigmaNonstat(thisRow["sigma0"], thisRow["sigma1"], yearStart), xiNonstat(thisRow["xi0"], thisRow["xi1"], yearStart)))
  
  #Analyze when all non-stationary
  params8Vector <- apply(params8NG, 1, function(thisRow) qevd(qevdProb, muNonstat(thisRow["mu0"], thisRow["mu1"], yearStart), sigmaNonstat(thisRow["sigma0"], thisRow["sigma1"], yearStart), xiNonstat(thisRow["xi0"], thisRow["xi1"], yearStart)))
  
  #The final set in setting up is creating a dataframe out of these vectors
  parameterDataFrame <- data.frame(params1Vector, params2Vector, params3Vector, params4Vector, params5Vector, params6Vector, params7Vector, params8Vector)
}
```

```{r}

#Use this chunk of code to find values where USACE extends beyond BMA 

#Create a vector of weights here - remember, MUST ADD TO 1
#We will read in the RDS file Tony created in the 'outputs' folder with his BMA weights
weightVector <- readRDS('../output/bma_weights_uniform.rds')

#Use the functions in order to get the necessary vectors and graph them against one another
USACEDistribution <- generateUSACE(seaLevelData = LSL85, statParams = params1NG, timeProj = timeProj, iterations = 10000, yearStart = 2016, yearEnd = 2025, returnPeriod = 100, uniformStart = 1.5, uniformEnd = 2)

weightedDistribution <- BMAWeights(year = 2025, qevdProb = 0.99, weightVector = weightVector, paramSet = 2, iterations = 10000)


print(paste("Min of BMA:", min(weightedDistribution), sep = ""))
print(paste("Min of USACE:", min(USACEDistribution), sep = ""))
print(paste("Max of BMA:", max(weightedDistribution), sep = ""))
print(paste("Max of USACE:", max(USACEDistribution), sep = ""))

```

```{r}

#Now, use ther above functions as a part of a larger function that will perform rejection sampling
#yearStart = the starting year for calculating sea level rise
#yearEnd = the ending year for calculating sea level rise AND the year used for rejection sampling
#returnPeriod = how often we expect to see a given storm
#iterations = how many iterations perofromed for the weightedDistribution and generateUSACE functions
#weightVector = a vector of BMA weights
#uniformStart = the start of a uniform distribution to pull surge factors from
#uniformEnd = the end of a uniform ditribution to pull surge factors from
rejectionSampling <- function(yearStart = 2016, yearEnd = 2065, returnPeriod = 100, iterations = 10000, weightVector = weightVector, uniformStart = 1.5, uniformEnd = 2){
  
  #Begin by generating a BMA weighted distribtuon and building an approximation of the density
  #We use paramSet = 2 because we only want the normal gamma data for this portion of our research
   #Note that 1-(1/returnPeriod) is equal to our qevd probability
  weightedDistribution <- BMAWeights(year = yearEnd, qevdProb = 1-(1/returnPeriod), weightVector = weightVector, iterations = iterations, paramSet = 2)
  
  densityWeighted <- density(weightedDistribution)
  weightedFunctionFit <- approxfun(densityWeighted$x, densityWeighted$y)
  
  #Now, do the same process as above for the USACE distribution
  USACEDistribution <- generateUSACE(seaLevelData = LSL85, statParams = params1NG, timeProj = timeProj, iterations = iterations, yearStart = yearStart, yearEnd = yearEnd, returnPeriod = returnPeriod, uniformStart = uniformStart, uniformEnd = uniformEnd)
  
  densityUSACE <- density(USACEDistribution)
  USACEFunctionFit <- approxfun(densityUSACE$x, densityUSACE$y)
  
  #Now, begin the rejection sampling portion
  #Will go through many iterations, pulling a surge factor, GEV parameters, and sea-level rise sample each time
  #Will use these values to calculate the return level in the projection year
  #If the probability of seeing that return level is higher than a randomly-drawn boundary, add the surge factor, sea level change, and GEV params to vectors
  
  #Begin by initializing emptry vectors for the values we will store
  surgeVector <- c()
  seaLevelVector <- c()
  muVector <- c()
  sigmaVector <- c()
  xiVector <- c()
      
  for(i in 1:iterations){
  #Begin by sampling fromLSL85, which contains sea level projections
  #Generate a random index and calculate the change from yearStart to yearEnd
  sampleIndex <- sample(1:ncol(LSL85), 1)
  startRow = which(timeProj == yearStart)
  endRow = which(timeProj == yearEnd)
    
  seaLevelChange <- (LSL85[endRow, sampleIndex] - LSL85[startRow, sampleIndex])
    
  #Now, sample the GEV parameters using params1NG, the normal gamma stationary parameters from Tony
  sampleIndex = sample(1:nrow(params1NG), 1)
  sampleMu <- params1NG[sampleIndex, "mu"]
  sampleSigma <- params1NG[sampleIndex, "sigma"]
  sampleXi <- params1NG[sampleIndex, "xi"]
  
  #Finally, sample from the uniform distribution to get the surge factor
  #Important note: This is the same distribution as used in our approximation function
  surgeFactor <- runif(1, uniformStart, uniformEnd)
    
  #Now, calculate the return level using the sationary parameters sampled above
  #Note that 1-(1/returnPeriod) is equal to our qevd probability
  returnLevel <- qevd(1-(1/returnPeriod), sampleMu, sampleSigma, sampleXi)
    
  #Modify that value using the sampled surge factor and change in sea level
  #This follows how the USACE crrently models flood level projections
  returnLevel <- returnLevel + (surgeFactor * seaLevelChange)
  
  #For rejection sampling, the probability of accepting the surge factor is the ratio of the probability we see the return level in the weighted distirbtuion to the probaiity we see the return level in the USACE distribtuion
  #We take the min of (1, ratio) in case the ratio is higher than 1
  #In that case, we would always expect to see the return level we calculated
  surgeProbability = min(1, weightedFunctionFit(returnLevel)/USACEFunctionFit(returnLevel))
  
  #Next, we compare that probability to a probabilty drawn from a uniform distribution from 0 to 1
  #If surgeProbability is greater, add that surge factor to our vector along with the sea level change and GEV params
  #If surgeProbability is smaller, don't do anything
  
  acceptanceBoundary = runif(1, 0, 1)
  
  #This covers the case where the boundaries of the BMA extend beyond the USACE function
  #We don't want this to happen in rejection sampling, but it stops errors from being thrown when playing around
  if(is.na(surgeProbability)){
    surgeProbability = 0
  }
  
  if(surgeProbability > acceptanceBoundary){
    surgeVector <- append(surgeVector, surgeFactor)
    seaLevelVector <- append(seaLevelVector, seaLevelChange)
    muVector <- append(muVector, sampleMu)
    sigmaVector <- append(sigmaVector, sampleSigma)
    xiVector <- append(xiVector, sampleXi)
  }
  
  }
  
  #Finally, create a dataframe out of the vectors
  rejectionDataFrame <- data.frame(surgeVector, seaLevelVector, muVector, sigmaVector, xiVector)
  
  return(rejectionDataFrame)
  
}

rejectionDataFrame <- rejectionSampling(yearStart = 2016, yearEnd = 2020, returnPeriod = 20, iterations = 10000, weightVector = weightVector, uniformStart = 0, uniformEnd = 2)
```

```{r}
getSurges <- rejectionDataFrame[["surgeVector"]]
hist(getSurges)
```

