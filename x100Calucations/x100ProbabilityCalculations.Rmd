---
title: "Torline - 2019 - Research - 1"
author: "Travis Torline"
date: "6/15/2019"
---

```{r}
#Begin by loading the packages we'll need to perform our analysis
library("extRemes")
library(ncdf4)

#Now, read in all of the CSV files and store them
params1 <- read.csv(file="params1.csv", header=TRUE, sep=",") #All stationary
params2 <- read.csv(file="params2.csv", header=TRUE, sep=",") #Mu nonstationary
params3 <- read.csv(file="params3.csv", header=TRUE, sep=",") #Sigma nonstationary
params4 <- read.csv(file="params4.csv", header=TRUE, sep=",") #Xi nonstatioanry
params5 <- read.csv(file="params5.csv", header=TRUE, sep=",") #Sigma/Xi nonstationary
params6 <- read.csv(file="params6.csv", header=TRUE, sep=",") #Mu/Xi nonstationary
params7 <- read.csv(file="params7.csv", header=TRUE, sep=",") #Mu/Sigma nonstationary
params8 <- read.csv(file="params8.csv", header=TRUE, sep=",") #All nonstationary


#The following is code from advisor Tony Wong to read in and normalize historical temperature data from NOAA
#The variables we'll need from this are 'temperature_proj' and 'time_proj'
##=============================================================================
## read_temperature_data.R
##
## read temperature data
## historical from NOAA:
##   NOAA National Centers for Environmental information, Climate at a Glance:
##   Global Time Series, published May , retrieved on June 7,  from
##   http://www.ncdc.noaa.gov/cag/
## future projections from CRNM under RCP8.5, part of CMIP5
##
## Questions? Tony Wong (anthony.e.wong@colorado.edu)
##=============================================================================

# read the projections temperature forcing from CRNM (CMIP5)
# note: these are in K, but going to normalize, so will take a difference and
# it's same as celsius
ncdata <- nc_open('global.tas.aann.CNRM-CM5.historical+rcp85.r1i1p1.18500101-21001231.nc')
temperature_proj <- ncvar_get(ncdata, 'tas')
time_proj <- ncvar_get(ncdata, 'time')
nc_close(ncdata)

# 'time' on the netcdf ile is YYYYMMDD, where MMDD is July 2 each year (becuase
# of the averaging). so pluck off just the years
time_proj <- floor(time_proj/10000)

# read the historical forcing from NOAA
data.tmp <- read.table('noaa_temperature_1880-2017.csv', header = TRUE, sep=',')
time_hist <- data.tmp$Year
temperature_hist <- data.tmp$Value

# extend historical back to 1850 with HadCRUT4
data.tmp = read.table('HadCRUT.4.4.0.0.annual_ns_avg.txt')
time_hadcrut = data.tmp[,1]
temperature_hadcrut = data.tmp[,2]

# normalize all to 1901-2000
ind_norm <- which(time_hist==1901):which(time_hist==2000)
temperature_hist <- temperature_hist - mean(temperature_hist[ind_norm])

ind_norm <- which(time_hadcrut==1901):which(time_hadcrut==2000)
temperature_hadcrut <- temperature_hadcrut - mean(temperature_hadcrut[ind_norm])

ind_norm <- which(time_proj==1901):which(time_proj==2000)
temperature_proj <- temperature_proj - mean(temperature_proj[ind_norm])

# set up the forcing, wherein the historical starts, then projections finish
# 1850-1880 -- hadcrut4
# 1880-2016 -- NOAA historical
# -2100 -- CRNM projection
time_forc <- min(time_hadcrut):max(time_proj)
temperature_forc <- rep(NA, length(time_forc))

ind_hadcrut <- which(time_hadcrut==time_forc[1]):(which(time_hadcrut==time_hist[1])-1)
ind_hist    <- 1:length(time_hist)
ind_proj    <- which(time_proj==(max(time_hist)+1)):which(time_proj==max(time_forc))

temperature_forc <- c(temperature_hadcrut[ind_hadcrut],
                      temperature_hist[ind_hist]      ,
                      temperature_proj[ind_proj]      )

# maximum temperature serves as an additinoal prior constraint on kappa0, kappa1
# that is, kappa1 > -kappa0/Tmax (otherwise, kappa = kappa0 + kappa1*T might be
# negative)  (not necessary for GEV models)
Tmax <- max(temperature_forc)

#Set up the formulas for nonstationary variables
#Each function takes a stationary parameter, non-stationary parameter, and time as inputs
#Each function calculates a new parameter value using the projected average temperature
#Note that because time_proj values start at 1850, but temperature_proj's indices start at 1, we subtract 1849
#Each function outputs the new parameter value


# TW:  
# - avoid assuming temperature_proj is an implicit input by making it an explicit function argument
# - can avoid hard-coding 1849 by instead assuming time and temperature inputs are same-length
#   arrays and finding the proper index/indices as temperature[which(time==time_i_want)]
#   (where temperature and time are arrays and time_i_want is the year we want the projection in)

muNonstat <- function(mu0, mu1, time){
  newMu <- mu0 + mu1 * temperature_proj[time - 1849]
}

sigmaNonstat <- function(sigma0, sigma1, time){
  newSigma <- exp(sigma0 + sigma1 * temperature_proj[time - 1849])
}

xiNonstat <- function(xi0, xi1, time){
  newXi <- xi0 + xi1 * temperature_proj[time - 1849]
}
```

```{r}
# TW: 
# - can simply plug in 2000 as the first argument into pevd
# - can reference parameters as (e.g.) params1[i,"m"] to avoid confusion, more readable
# - avoid hard-coding ensemble size, 2064, here and throughout
# - want the exceedance probability, so 1-pevd(...)
# - try to set this up using sapply(...) instead of the for loop

#Analyze when all parameters are staionary, params1
#Go through all sets of parameters and calcuate the pevd for each
#pevdVector[2000] gives the probability of a sea level equal to or less than 2000mm
params1Vector <- c()
for(i in 1:2064){
  params1Vector <- append(params1Vector, pevd(0:2000, params1[i,2], params1[i,3], params1[i,4])[2000])
}

#Analyze when mu is non-stationary, params2
#First calculate the new value of mu using the year 2065
#Then use the same format as  explained in params1

# TW:
# - avoid hard-coding 216 here and throughout. instead, do:  
# year_proj <- 2016 # or whatever year you want
# newMu <- muNonstat(params2[i,"u0"], params2[i,"u1"], time_proj[which(time_proj==2016)])
# (or something like that; probably the nonstat functions will change a little)

params2Vector <- c()
for(i in 1:2064){
  newMu <- muNonstat(params2[i,2], params2[i,3], time_proj[216])
  
  params2Vector <- append(params2Vector, pevd(0:2000, newMu, params2[i,4], params2[i,5])[2000])
}

#Analyze when Sigma non-stationary
params3Vector <- c()
for(i in 1:2064){
  newSigma <- sigmaNonstat(params3[i,3], params3[i,4], time_proj[216])
  
  params3Vector <- append(params3Vector, pevd(0:2000, params3[i,2], newSigma, params3[i,5])[2000])
}

#Analyze when xi non-stationary
params4Vector <- c()
for(i in 1:2064){
  newXi <- xiNonstat(params4[i,4], params4[i,5], time_proj[216])
  
  params4Vector <- append(params4Vector, pevd(0:2000, params4[i,2], params4[i,3], newXi)[2000])
}

#Analyze when sigma, xi non-stationary
params5Vector <- c()
for(i in 1:2064){
  newSigma <- sigmaNonstat(params5[i,3], params5[i,4], time_proj[216])
  newXi <- xiNonstat(params5[i,5], params5[i,6], time_proj[216])
  
  params5Vector <- append(params5Vector, pevd(0:2000, params5[i,2], newSigma, newXi)[2000])
}

#Analyze when mu, xi non-stationary
params6Vector <- c()
for(i in 1:2064){
  newMu <- muNonstat(params6[i,2], params6[i,3], time_proj[216])
  newXi <- xiNonstat(params6[i,5], params6[i,6], time_proj[216])
  
  params6Vector <- append(params6Vector, pevd(0:2000, newMu, params6[i,4], newXi)[2000])
}

#Analyze when mu, sigma non-stationary
params7Vector <- c()
for(i in 1:2064){
  newMu <- muNonstat(params7[i,2], params7[i,3], time_proj[216])
  newSigma <- sigmaNonstat(params7[i,4], params7[i,5], time_proj[216])
  
  params7Vector <- append(params7Vector, pevd(0:2000, newMu, newSigma, params7[i,6])[2000])
}

#Analyze when all non-stationary
params8Vector <- c()
for(i in 1:2064){
  newMu <- muNonstat(params8[i,2], params8[i,3], time_proj[216])
  newSigma <- sigmaNonstat(params8[i,4], params8[i,5], time_proj[216])
  newXi <- xiNonstat(params8[i,6], params8[i,7], time_proj[216])
  
  params8Vector <- append(params8Vector, pevd(0:2000, newMu, newSigma, newXi)[2000])
}

#Just playing around with some plotting of functions in the exTremes package
params1[1,2]
plot(0:3000, devd(0:3000, params1[1,2], params1[1,3], params1[1,4]), type = "l")
plot(pevd(0:3000, params1[1,2], params1[1,3], params1[1,4]))
cdfVector <- pevd(0:4000, params1[1,2], params1[1,3], params1[1,4])

cdfVector[4000]
```

```{r}
hist(params1Vector, freq = FALSE, border = "white")
hist(params2Vector, freq = FALSE, add = T, border = "white")
hist(params3Vector, freq = FALSE, add = T, border = "white")
hist(params4Vector, freq = FALSE, add = T, border = "white")

lines(density(params1Vector), col = "red")
lines(density(params2Vector), col = "blue")
lines(density(params3Vector), col = "green")
lines(density(params4Vector))

pevd(0:2000, newMu, newSigma, newXi)[2000]
```

```{r}
params2Vector <- c()
for(i in 1:2064){
  newMu <- muNonstat(params2[i,2], params2[i,3], time_proj[216])
  
  pevdVector <- pevd(0:2000, newMu, params2[i,4], params2[i,5])
  params2Vector <- append(params2Vector, pevdVector[2000])

}

hist(params2Vector, border = "white", freq = FALSE, main = "Density of Probabilities - 2017 vs 2065")
legend("topleft", c("2065", "2017"), fill = c("black", "red"))
lines(density(params2Vector))

params2Vector <- c()
for(i in 1:2064){
  newMu <- muNonstat(params2[i,2], params2[i,3], time_proj[178])
  
  pevdVector <- pevd(0:2000, newMu, params2[i,4], params2[i,5])
  params2Vector <- append(params2Vector, pevdVector[2000])

}

hist(params2Vector, border = "white", freq = FALSE, add = T)
lines(density(params2Vector), col = "red")
```

